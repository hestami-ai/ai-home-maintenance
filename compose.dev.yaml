name: hestami-ai-dev

networks:
  backend-dev:
    name: backend-dev
    driver: bridge
  temporal-network:
    name: temporal-network
    external: true
    driver: bridge

volumes:
  hestami_media_data_dev:
  postgres_data_dev:
  elasticsearch_data_dev:
  ollama_models_dev:
    driver: local

services:
  init-volumes:
    image: busybox
    container_name: init-volumes-dev
    volumes:
      - "./volumes/dev/static/hestami_media_data_dev:/mnt/hestami-static:rw"
    command: >
      /bin/sh -c "mkdir -p /mnt/hestami-static/media /mnt/hestami-static/static &&
      chown -R 999:999 /mnt/hestami-static &&
      chmod -R 775 /mnt/hestami-static"
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"

  frontend:
    build: 
      context: .
      dockerfile: ./docker/frontend/sveltekit/Dockerfile
      args:
        ENV_NPM_BUILD_FILE: ./.env.local
    container_name: frontend-dev
    ports:
      - "3000:3000"
    env_file:
      - ./.env.local
    environment:
      - BODY_SIZE_LIMIT=104857600  # 100MB in bytes
    networks:
      - backend-dev
    depends_on:
      - api
      - static
      - traefik
    deploy:
      resources:
        limits:
          memory: 2G  # Allow ~20 concurrent 100MB uploads
        reservations:
          memory: 512M  # Base memory for app
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.frontend.rule=Host(`homeservices.hai`)"
      - "traefik.http.routers.frontend.tls=true"
      - "traefik.http.services.frontend.loadbalancer.server.port=3000"
      # Enable request buffering for large uploads
      - "traefik.http.middlewares.frontend-buffering.buffering.maxRequestBodyBytes=104857600"  # 100MB
      - "traefik.http.middlewares.frontend-buffering.buffering.memRequestBodyBytes=104857600"  # 100MB in memory
      - "traefik.http.routers.frontend.middlewares=frontend-buffering"
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  
  api:
    build: 
      context: .
      dockerfile: ./docker/backend/django/Dockerfile
    container_name: api-dev
    command: python manage.py runserver 0.0.0.0:8050
    volumes:
      - ./backend/django/hestami_ai_project:/app:rw
      - "./volumes/dev/static/hestami_media_data_dev:/mnt/hestami-static:rw"
    depends_on:
      - db
      - redis
      - clamav
      - static
      - init-volumes
    ports:
      - "8050:8050"
    env_file:
      - ./.env.local
    networks:
      - backend-dev
      - temporal-network
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  db:
    image: postgres:17
    container_name: db-dev
    env_file:
      - ./.env.local
    ports:
      - "5432:5432"
    volumes:
      - postgres_data_dev:/var/lib/postgresql/data
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  static:
    build: 
      context: ./backend/static
      dockerfile: ../../docker/backend/static/Dockerfile
    container_name: static-dev
    restart: unless-stopped
    ports:
      - "8090:80"
    volumes:
      - "./volumes/dev/static/hestami_media_data_dev/templates/etc/nginx:/templates/etc/nginx:ro"
      - "./volumes/dev/static/hestami_media_data_dev:/usr/share/nginx/html/:ro"
    env_file:
      - ./.env.local
    command: >
      /bin/sh -c "envsubst '$$NGINX_SECURE_LINK_SECRET' < /templates/etc/nginx/nginx.conf.template > /etc/nginx/nginx.conf 
      && exec nginx -g 'daemon off;'"
    networks:
      - backend-dev
    depends_on:
      - init-volumes
      - traefik
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.static.rule=Host(`static.hai`)"
      - "traefik.http.routers.static.tls=true"
      - "traefik.http.services.static.loadbalancer.server.port=80"
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  ai-agents:
    build:
      context: .
      dockerfile: ./docker/backend/fastapi/Dockerfile
    container_name: ai-agents-dev
    volumes:
      - ./backend/fastapi:/app
    environment:
      - PYTHONPATH=/app
    ports:
      - "8001:8001"
    env_file:
      - .env.local
    depends_on:
      - redis
      - elasticsearch
      - ollama
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  redis:
    image: redis:8.0-M02-alpine3.20
    container_name: redis-dev
    ports:
      - "6379:6379"
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"
  clamav:
    image: clamav/clamav:stable
    container_name: clamav-dev
    ports:
      - "3310:3310"
    environment:
      - CLAMAV_NO_MILTERD=true
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"   
  elasticsearch:
    image: elasticsearch:8.11.1
    container_name: elasticsearch-dev
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - cluster.routing.allocation.disk.threshold_enabled=false
    volumes:
      - elasticsearch_data_dev:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - backend-dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"   
  vllm_container:
    image: vllm/vllm-openai:latest
    container_name: vllm-container-dev
    runtime: nvidia
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    env_file:
      - ./.env.local
    ports:
      - "8000:8000"
    volumes:
      - "./volumes/dev/vllm/.cache/huggingface:/root/.cache/huggingface:rw"
    ipc: "host"
    command: >
      --model Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4
    # "Qwen/Qwen2.5-3B-Instruct"
    # "Qwen/Qwen2.5-14B-Instruct-GPTQ-Int4"

  ollama:
    build:
      context: ./docker/backend/ollama
      dockerfile: Dockerfile
    container_name: ollama-dev
    environment:
      - OLLAMA_DEFAULT_MODEL=qwen3:4b-q4_K_M
      - OLLAMA_CONTEXT_LENGTH=40960
      - OLLAMA_FLASH_ATTENTION=true
      - OLLAMA_INTEL_GPU=true
      - OLLAMA_NEW_ENGINE=true
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_NUM_PARALLEL=1
      - OLLAMA_MULTIUSER_CACHE=true
    ports:
      - "11434:11434"
    volumes:
      - ollama_models_dev:/root/.ollama
      - "./volumes/dev/ollama/models/config:/root/ollama/models/config:rw"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"   
  temporal-workers:
    build:
      context: .
      dockerfile: ./docker/backend/temporal-workers/Dockerfile
    container_name: temporal-workers-dev
    volumes:
      - ./backend/temporal-workers/src:/app/src:rw
    env_file:
      - ./.env.local
    networks:
      - backend-dev
      - temporal-network
    depends_on:
      - api
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"   
  html-chunker:
    build:
      context: .
      dockerfile: ./docker/backend/html-chunker/Dockerfile
    container_name: html-chunker-dev
    env_file:
      - ./.env.local
    ports:
      - "8070:8000"
    volumes:
      - "./volumes/dev/html-chunker:/root/html-chunker:rw"
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"   

  traefik:
    image: traefik:v3.2.1
    container_name: traefik-dev
    command:
      - "--api.insecure=false"
      - "--providers.docker=true"
      - "--providers.docker.exposedbydefault=false"
      - "--providers.docker.network=backend-dev"
      - "--entrypoints.websecure.address=:443"
      - "--entrypoints.websecure.http.tls=true"
      - "--providers.file.directory=/etc/traefik/certs"
      - "--providers.file.watch=true"
      - "--log.level=DEBUG"
      - "--accesslog=true"
      - "--accesslog.filepath=/var/log/traefik/access.log"
      # Optimize for large file uploads
      - "--entrypoints.websecure.transport.respondingTimeouts.readTimeout=300s"
      - "--entrypoints.websecure.transport.respondingTimeouts.writeTimeout=300s"
      - "--entrypoints.websecure.transport.respondingTimeouts.idleTimeout=180s"
      # Increase max request body size for file uploads (100MB)
      - "--entrypoints.websecure.http.middlewares=upload-limit@docker"
      # HTTP/2 settings for large uploads
      - "--entrypoints.websecure.http2.maxConcurrentStreams=250"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "443:443"
    volumes:
      - "./volumes/dev/traefik/certs:/etc/traefik/certs:ro"
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "./volumes/dev/traefik/logs:/var/log/traefik"
    networks:
      - backend-dev
    logging:
      driver: "local"
      options:
        max-size: "20m"
        max-file: "5"  